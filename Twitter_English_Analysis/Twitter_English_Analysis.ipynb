{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<p><font size=7 color=\"#2E1698\"><u><center>Twitter English Analysis</center></u></font></p>\n",
    "<p><font size=4.5 color=\"#2E1698\"><i><center>Bonus: fast Analysis for introduce English known packages</center></i></font></p><br>\n",
    "<p><font size=3.2 color=\"#2E1698\"><i><u>Introduction:</u></i>We are here aiming to manipulate the data that we generated before in the recover notebook. Our data was provided by the Twitter API and was filtring with the '#Lalaland' hashtag. We recovered our data Thursday 4th February 2017 on week after it theatrical release.</font><p>\n",
    "<br>\n",
    "<font color=\"#206B50\" size = 4.5><center>**SUMMARY**</center></font>\n",
    "<font size=3.2 color=\"#2E1698\">\n",
    "<b>Part I: Same work as for french analysis</b>\n",
    "      <ol>\n",
    "          <li>Data visualization</li>\n",
    "          <li>Data cleaning</li>\n",
    "          <li>List of the most frequent words</li>\n",
    "      </ol>\n",
    "<br>\n",
    "<b>Part II: Bonus</b>\n",
    "      <ol>\n",
    "          <li>Sentiment Analysis : RSentiment</li>\n",
    "          <li>Sentiment Analysis : syuzhet</li>\n",
    "          <li>Graphic Representation</li>\n",
    "      </ol>\n",
    "<br>\n",
    "</font>\n",
    "<br>\n",
    "\n",
    "<p><font size=4.5 color=\"#206B50\"><center><B>PART I - 1. DATA VISUALIZATION</B></center></font></p>\n",
    "<font size=3 color=\"#2E1698\">First things first, let's import the csv file. We are using french tweets this is why we need to specify the UTF-8 encoding. To have a better idea of our database we decided to show the first 5 lines.</font><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Packages needed\n",
    "\n",
    "#In order to have install_github function\n",
    "#install.packages(\"devtools\")\n",
    "#library(devtools)\n",
    "\n",
    "#wordcloud2\n",
    "#install_github(\"lchiffon/wordcloud2\")\n",
    "\n",
    "#others\n",
    "'install.packages(\"tm\")\n",
    "install.packages(\"RSentiment\") #Requiered Java \n",
    "install.packages(\"plyr\")\n",
    "install.packages(\"syuzhet\")\n",
    "install.packages(\"wordcloud\")\n",
    "install.packages(\"SnowballC\")\n",
    "'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "yourPath = paste0(getwd(),\"/data/Lalaland.csv\")\n",
    "\n",
    "tweets = read.csv(yourPath, encoding=\"UTF-8\")\n",
    "print(dim(tweets))\n",
    "\n",
    "tweets <- subset(tweets, select=-c(replyToSN,replyToUID, replyToSID, latitude, longitude, favorited))\n",
    "#head(tweets, n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<font color=\"#2E1698\" size = 3.2>As you can see, our data frame contains <font color=\"red\">17</font> columns and <font color=\"red\">1 000</font> rows, let's see the 5 firsts rows.</font>\n",
    "<br>\n",
    "<br>\n",
    "<p><font size=4.5 color=\"#206B50\"><center><B>PART I - 2. DATA CLEANING</B></center></font></p>\n",
    "<font color=\"#2E1698\" size = 3.2>If we want to use the text, it have to be cleaned first.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "clean_text = function(x)\n",
    "{\n",
    "    #To convert the text in lowercase\n",
    "    try.error = function(z)\n",
    "    {\n",
    "        y = NA\n",
    "        try_error = tryCatch(tolower(z), error=function(e) e)\n",
    "            if (!inherits(try_error, \"error\"))\n",
    "                y = tolower(z)\n",
    "                return(y)\n",
    "    }\n",
    "            \n",
    "    x = sapply(x, try.error)\n",
    "            \n",
    "    #Replace Emma by Stone \n",
    "    x = gsub(\"emma\", \"stone\", x)\n",
    "    \n",
    "    #Delete unecessary #lalaland or lalaland       \n",
    "    x = gsub(\"#lalaland\\\\w+ *\", \"\", x) \n",
    "            \n",
    "     #remove all links starting by http\n",
    "    x = gsub('http\\\\S+\\\\s*', '', x)\n",
    "            \n",
    "    # replace apostrophes\n",
    "    x = gsub(\"'\", \" \", x)\n",
    "\n",
    "    # remove punctuation except @, #, _, -\n",
    "    x = gsub(\"@\", \"AAAAAAAAAAA\", x)\n",
    "    x = gsub(\"#\", \"BBBBBBBBBBB\", x)\n",
    "    x = gsub(\"_\", \"CCCCCCCCCCC\", x)\n",
    "    x = gsub(\"-\", \"DDDDDDDDDDD\", x)\n",
    "    x = gsub(\"[[:punct:]]\", \" \", x)\n",
    "    x = gsub(\"AAAAAAAAAAA\", \"@\", x)\n",
    "    x = gsub(\"BBBBBBBBBBB\", \"#\", x)\n",
    "    x = gsub(\"CCCCCCCCCCC\", \"_\", x)\n",
    "    x = gsub(\"DDDDDDDDDDD\", \"-\", x)\n",
    "            \n",
    "    # correcting the spaces after the conserved @\n",
    "    x = gsub(\"@ \", \"@\", x)\n",
    "            \n",
    "    # correcting the spaces after the conserved _\n",
    "    x = gsub(\"_ \", \"_\", x)\n",
    "            \n",
    "    # correcting the spaces after the conserved -\n",
    "    x = gsub(\"- \", \"-\", x)\n",
    "    \n",
    "    # remove numbers/Digits\n",
    "    x = gsub(\"[[:digit:]]\", \"\", x)\n",
    "    \n",
    "    # remove tabs\n",
    "    x = gsub(\"[ |\\t]{2,}\", \" \", x)\n",
    "            \n",
    "    # remove blank spaces at the beginning/end\n",
    "    x = gsub(\"^ \", \"\", x)  \n",
    "    x = gsub(\" $\", \"\", x)\n",
    "    x = gsub(\"'\", \"\", x)    \n",
    "    \n",
    "    # As we have already a column indicating if the tweet is a retweet or not \n",
    "    # we can remove \"RT @xxx\" in the tweet header\n",
    "    x = gsub(\"rt @\\\\w+ *\", \"\", x)\n",
    "    x = gsub('\\\\b\\\\w{1,3}\\\\s','', x)\n",
    "            \n",
    "    # remove double spaces\n",
    "    x = gsub(\"  \", \" \", x)\n",
    "    x = gsub(\"  \", \" \", x)\n",
    "    return(x)\n",
    "}\n",
    "                             \n",
    "tweets$text_cleaned <- clean_text(tweets$text)\n",
    "tweets$text <- clean_text(tweets$text)\n",
    "#head(tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<font color=\"#2E1698\" size = 3.2>\n",
    "As we selected only english tweets in our recover notebook, there is tweets without text, so the datraframe display NA in some text lines that we have to delete. \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sum(is.na(tweets$text_cleaned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tweets = na.omit(tweets)\n",
    "tweets$X <- NULL\n",
    "nrow(tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<font color=\"#2E1698\" size = 3.2>\n",
    "There is now <font color = \"darkred\" size = 3.2>742</font> lines in our dataframe. <br><br>\n",
    "<p><font size=4.5 color=\"#206B50\"><center><B>PART I - 3. LIST OF THE MOST FREQUENT WORDS</B></center></font></p>\n",
    "Let's see which are the most used @xxx and replace them with words. Afterward we will delete all the @xxx that will not be replaced.<br> \n",
    "To do that, we created a function called number_Top able to recover words most used according to:\n",
    "<ol>\n",
    "<li>A specific pattern / first argument</li>\n",
    "<li>The N number of words you want to return / second argument</li>\n",
    "<li>The way you want to diplay it: decreasing = TRUE or FALSE / third argument</li>\n",
    "</ol>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "number_Top = function(column ,at.pattern, number, Topdecreasing){\n",
    "\n",
    "    have.at = grep(x = column, pattern = at.pattern)\n",
    "    at.matches = gregexpr(pattern = at.pattern, text = column[have.at])\n",
    "    extracted.at = regmatches(x = column[have.at], m = at.matches)\n",
    "\n",
    "    # most frequent words\n",
    "    most_f_words = sort(unlist(extracted.at), decreasing=TRUE)\n",
    "    most_f_words = gsub(\" \", \"\", most_f_words)\n",
    "    words = sort(table(unlist(most_f_words)), decreasing=TRUE)\n",
    "    \n",
    "    topWord = head(words, n = number)\n",
    "    topWord = sort(topWord, decreasing=Topdecreasing) \n",
    "    return(topWord)\n",
    "}\n",
    "\n",
    "top5 = number_Top(tweets$text_cleaned, \"@\\\\w+ *\", 5, TRUE)\n",
    "barplot(sort(top5), border=NA, las=2, main=\"Top 5 most frequent user acount\", cex.main=1, horiz=TRUE, col= \"darkblue\", cex.names=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<font color=\"#2E1698\" size = 3.2>\n",
    "Now that we have seen the user account most used, we want to change it as simple words.<br>\n",
    "Then '@ryangosling' will be simply 'Gosling'. After that we will delete all # and @ characters.<br>\n",
    "Finally, using our previous function, and just by changing our pattern we will display the 15 most frequent words.<br>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "clean_name_text = function(x)\n",
    "{\n",
    "    x = gsub('\\\\S+goslin\\\\S+', 'gosling', x)\n",
    "    x = gsub(\"@\", \"\", x)\n",
    "    x = gsub(\"#\", \"\", x)\n",
    "}\n",
    "\n",
    "tweets$text_cleaned <- clean_name_text(tweets$text_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "top15 = number_Top(tweets$text_cleaned, \"[a-zA-Z]\\\\w+ *\", 15, TRUE)\n",
    "barplot(sort(top15), border=NA, las=2, main=\"Top 15 most frequent word\", cex.main=1, horiz=TRUE, col= \"darkblue\", cex.names=0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<font color=\"#2E1698\" size = 3.2>\n",
    "As we can see there is words like \"this\" or \"with\" not really meaningful.<br>\n",
    "English language is very convenient because it allows us to delete easily the common words being in the stopwords('english') tm function. <br>\n",
    "We have to create a regex on each value of this vector that we will use in order to delte each of those stopwords in our text.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#install.packages(\"tm\")\n",
    "library(tm)\n",
    "stopwords('french')\n",
    "stopwords_regex = paste(c(stopwords('english'), \"just\", \"behind\"), collapse = '\\\\b|\\\\b')\n",
    "stopwords_regex = paste0('\\\\b', stopwords_regex, '\\\\b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tweets$text_cleaned = stringr::str_replace_all(tweets$text_cleaned, stopwords_regex, '')\n",
    "\n",
    "top15 = number_Top(tweets$text_cleaned, \"[a-zA-Z]\\\\w+ *\", 15, TRUE)\n",
    "barplot(sort(top15), border=NA, las=2, main=\"Top 15 most frequent without stopwords\", cex.main=1, horiz=TRUE, col= \"darkblue\", cex.names=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<p><font size=4.5 color=\"#206B50\"><center><B>PART II - 1. SENTIMENT ANALYSIS: RSENTIMENT</B></center></font></p>\n",
    "<font color=\"#2E1698\" size = 3.2>\n",
    "Let's introduce the RSentiment Package. This package has a function called calculate score which return a numeric vector according to the sentence emotion. For each tweet, we sum the vector values and return a score. \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#install.packages(\"RSentiment\") #Requiered Java \n",
    "library(RSentiment)\n",
    "\n",
    "tweets$score = 0\n",
    "for (i in 1:nrow(tweets)){\n",
    " tweets$score[i] = sum(calculate_score(tweets$text[i]))   \n",
    "}\n",
    "\n",
    "tweets <- tweets[, c(1, 11, 12)]\n",
    "head(tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<font color=\"#2E1698\" size = 3.2>\n",
    "There is also a function 'calculate_total_presence_sentiment' which allows us return the summarized tweets sentiment.\n",
    "We just have to transpose the dataframe and then it's will be easy to show a meaningful barplot.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#install.packages(\"plyr\")\n",
    "library(plyr)\n",
    "\n",
    "Global_Lalaland_Sentiment = calculate_total_presence_sentiment(tweets$text_cleaned)\n",
    "Global_Lalaland_Sentiment\n",
    "Global_Lalaland_Sentiment = data.frame(t(Global_Lalaland_Sentiment))\n",
    "Global_Lalaland_Sentiment = rename(Global_Lalaland_Sentiment, c(\"X1\"=\"Emotions\", \"X2\"=\"Score\"))\n",
    "Global_Lalaland_Sentiment\n",
    "\n",
    "barplot(as.numeric(Global_Lalaland_Sentiment$Score), names = Global_Lalaland_Sentiment$Emotions, cex.names= 0.65,\n",
    "  xlab = \"feelings\", ylab = \"Number of tweets having specific emotion\", col = \"darkblue\",\n",
    "  main=\"Emotions in Lalaland tweets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<p><font size=4.5 color=\"#206B50\"><center><B>PART II - 2. SENTIMENT ANALYSIS: SYUZHET</B></center></font></p>\n",
    "<font color=\"#2E1698\" size = 3.2>\n",
    "Furthermore, the syuzhet package has a 'get_nrc_sentiment' function which return if in a text there is: anger, anticipation, disgust, fear, joy, sadness, surprise, trust, negative or/and positive emotion.<br>\n",
    "So we created a column for each emotion.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#install.packages(\"syuzhet\")\n",
    "library(syuzhet)\n",
    "\n",
    "tweets$anger = 0\n",
    "tweets$anticipation = 0\n",
    "tweets$disgust = 0\n",
    "tweets$fear = 0\n",
    "tweets$joy = 0\n",
    "tweets$sadness = 0\n",
    "tweets$surprise = 0\n",
    "tweets$trust = 0\n",
    "tweets$negative = 0\n",
    "tweets$positive = 0\n",
    "\n",
    "for(i in 1:nrow(tweets)){\n",
    "  if(get_nrc_sentiment(tweets$text_cleaned[i])$anger > 0){\n",
    "    tweets$anger[i] = 1\n",
    "  }\n",
    "  if(get_nrc_sentiment(tweets$text_cleaned[i])$anticipation > 0){\n",
    "    tweets$anticipation[i] = 1\n",
    "  } \n",
    "  if(get_nrc_sentiment(tweets$text_cleaned[i])$disgust > 0){\n",
    "    tweets$disgust[i] = 1\n",
    "  }\n",
    "  if(get_nrc_sentiment(tweets$text_cleaned[i])$fear > 0){\n",
    "    tweets$fear[i] = 1\n",
    "  } \n",
    "  if(get_nrc_sentiment(tweets$text_cleaned[i])$joy > 0){\n",
    "    tweets$joy[i] = 1\n",
    "  } \n",
    "  if(get_nrc_sentiment(tweets$text_cleaned[i])$sadness > 0){\n",
    "    tweets$sadness[i] = 1\n",
    "  } \n",
    "  if(get_nrc_sentiment(tweets$text_cleaned[i])$surprise > 0){\n",
    "    tweets$surprise[i] = 1\n",
    "  } \n",
    "  if(get_nrc_sentiment(tweets$text_cleaned[i])$trust > 0){\n",
    "    tweets$trust[i] = 1\n",
    "  }\n",
    "  if(get_nrc_sentiment(tweets$text_cleaned[i])$negative > 0){\n",
    "    tweets$negative[i] = 1\n",
    "  } \n",
    "  if(get_nrc_sentiment(tweets$text_cleaned[i])$positive > 0){\n",
    "    tweets$positive[i] = 1\n",
    "  } \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<font color=\"#2E1698\" size = 3.2>\n",
    "Now we can sum each column to have a global idea of the emotion that emerges from this film. \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sum_anger = sum(tweets$anger)\n",
    "sum_anticipation = sum(tweets$anticipation)\n",
    "sum_disgust = sum(tweets$disgust)\n",
    "sum_fear = sum(tweets$fear)\n",
    "sum_joy = sum(tweets$joy)\n",
    "sum_sadness = sum(tweets$sadness)\n",
    "sum_surprise = sum(tweets$surprise)\n",
    "sum_trust = sum(tweets$trust)\n",
    "sum_negative = sum(tweets$negative)\n",
    "sum_positive = sum(tweets$positive)\n",
    "\n",
    "sum_feelings_names = c(\"anger\", \"anticipation\", \"disgust\", \n",
    "                       \"fear\", \"joy\", \"sadness\", \"surprise\",\n",
    "                      \"trust\", \"negative\", \"positive\")\n",
    "sum_feelings = c(sum_anger, sum_anticipation, sum_disgust, \n",
    "                 sum_fear, sum_joy, sum_sadness, sum_surprise, \n",
    "                 sum_trust, sum_negative, sum_positive)\n",
    "\n",
    "df_feelings = data.frame(sum_feelings_names, sum_feelings)\n",
    "\n",
    "barplot(df_feelings$sum_feelings, names = df_feelings$sum_feelings_names, cex.names= 0.65,\n",
    "  xlab = \"feelings\", ylab = \"Number of tweets having specific emotion\", col = \"darkblue\",\n",
    "  main=\"Emotions in Lalaland tweets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<p><font size=4.5 color=\"#206B50\"><center><B>PART II - 3. GRAPHIC REPRESENTATION</B></center></font></p>\n",
    "<font color=\"#2E1698\" size = 3.2>\n",
    "Just because it's fun, we display our results using a simple wordcloud and another one more  \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#install.packages(\"wordcloud\")\n",
    "#install.packages(\"SnowballC\")\n",
    "library(SnowballC)\n",
    "library(wordcloud)\n",
    "\n",
    "tweets$text_cleaned = gsub(\"\\\\blalaland\\\\b\", \"\", tweets$text_cleaned)\n",
    "tweets$text_cleaned = gsub(\"lalaland\", \"\", tweets$text_cleaned)\n",
    "\n",
    "top50 = number_Top(tweets$text_cleaned, \"[a-zA-Z]\\\\w+ *\", 50, TRUE)\n",
    "wordcloud(names(top50), top50, min.freq=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#require(devtools)\n",
    "#install_github(\"lchiffon/wordcloud2\")\n",
    "library(wordcloud2)\n",
    "\n",
    "top100 = number_Top(tweets$text_cleaned, \"[a-zA-Z]\\\\w+ *\", 100, TRUE)\n",
    "cat(\"The letterCloud function does not work on Jupyter notebook, if you are using markdown, you can uncomment this line.\")\n",
    "#letterCloud(top100, shape = 'star', wordSize = 1)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "R 3.3",
   "language": "R",
   "name": "ir33"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
