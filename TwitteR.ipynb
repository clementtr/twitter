{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><font size=5 color=\"#210F6E\"><em><u><center>Text Mining and sentiment analysis</center></u></em></font><p>\n",
    "<br>\n",
    "<font size=3 color=\"#2E1698\"><B><u>PARTIE I:</u> Data recover on Twitter </B></font>\n",
    "<br>\n",
    "<br>\n",
    "<font face=\"Gill Sans\" color=\"#261D7A\" size=\"3.2\">First we created an application on dev.twitter called 'TwitterR ESME'</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#install.packages(\"twitteR\")\n",
    "library(twitteR)\n",
    "\n",
    "setwd(\"/Users/clementtailleur/R/TwitteR\")\n",
    "\n",
    "# Create application on dev.twitter.com called 'TwitteR ESME'\n",
    "api_key <- \"QWvyjcma0R6JC2tsdcfrFOzxM\"\n",
    "api_secret <- \"uQ2pKwlaNU89GlhxZ2j4GEpoHs72ZvhNnzSDTV1Fy4inzqer4T\"\n",
    "access_token <- \"1643689316-sCnLf9J7aUse8HNG9bMi2MX5XG2fMbte0eHzqot\"\n",
    "access_token_secret <- \"aFJhot2jA1MCUwbMog0UeVdlO6YVv20SzqIpQ8ooUBqwd\"\n",
    "setup_twitter_oauth(api_key,api_secret,access_token,access_token_secret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Gill Sans\" color=\"#261D7A\" size=\"3.2\">Just to become familiar with twitteR, I decided to recover the last 20 tweets of one of my favorite twitter account and display only the last 10.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Winamax_tweets <- userTimeline(user = \"@WinamaxSport\",\n",
    " n = 20, includeRts = FALSE, retryOnRateLimit = 25)\n",
    "\n",
    "cat(\"Full size:\", length(Winamax_tweets))\n",
    "head(Winamax_tweets, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Gill Sans\" color=\"#261D7A\" size=\"3.2\">Now we can get a number n tweets containing the value of string placed in first argument. Note that the Twitter search API only goes back 1500 tweets <br>\n",
    "Let's recover 10.000 and 20.000 tweets with the '#PrimaireLeDébat' word and create a dataframe based around results.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "require(twitteR)\n",
    "#primaireTweets <- searchTwitter(\"#PrimaireLeDébat\", n=10000)\n",
    "primaireTweets <- searchTwitter(\"#PrimaireLeDébat\", n=20000)\n",
    " \n",
    "primaire_df <- do.call(\"rbind\", lapply(primaireTweets, as.data.frame))\n",
    "cat(\"Columns names:\\n\", names(primaire_df))\n",
    "cat(\"\\n\\n\\nPart of your dataframe:\")\n",
    "#head(primaire_df,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Gill Sans\" color=\"#261D7A\" size=\"3.2\">We create a csv file from our database.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#write.csv(primaire_df, file = \"debat_primaire_10000.csv\", append=TRUE) #append=TRUE to overwrite\n",
    "#write.csv(primaire_df, file = \"debat_primaire_10000.csv\")\n",
    "write.csv(primaire_df, file = \"debat_primaire_20000.csv\")\n",
    "nrow(primaire_df)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.2.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
