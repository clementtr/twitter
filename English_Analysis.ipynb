{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><font size=5 color=\"#210F6E\"><em><u><center>Fast Data Analysis for English tweets</center></u></em></font><p>\n",
    "<br>\n",
    "<font face=\"Gill Sans\" color=\"#261D7A\" size=\"3.2\">As we did before with #PrimaireLeDÃ©bat tweets we recovered tweets having the hashtag #Lalaland in the TwitteR_Recover repository</font><br><br>\n",
    "<font color=\"#206B50\" size = 3><center>**DATA CLEANING**</center></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yourPath = paste0(getwd(),\"/data/Lalaland407.csv\")\n",
    "\n",
    "tweets = read.csv(yourPath, encoding=\"UTF-8\")\n",
    "print(dim(tweets))\n",
    "\n",
    "tweets <- subset(tweets, select=-c(replyToSN,replyToUID, replyToSID, latitude, longitude, favorited))\n",
    "#head(tweets, n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clean_text = function(x)\n",
    "{\n",
    "    #To convert the text in lowercase\n",
    "    try.error = function(z)\n",
    "    {\n",
    "        y = NA\n",
    "        try_error = tryCatch(tolower(z), error=function(e) e)\n",
    "            if (!inherits(try_error, \"error\"))\n",
    "                y = tolower(z)\n",
    "                return(y)\n",
    "    }\n",
    "            \n",
    "    x = sapply(x, try.error)\n",
    "    \n",
    "    #Delete #equivalent\n",
    "    x = gsub(\"#primaire\\\\w+ *\", \"\", x)\n",
    "            \n",
    "     #remove all links starting by http\n",
    "    x = gsub('http\\\\S+\\\\s*', '', x)\n",
    "            \n",
    "    # replace apostrophes\n",
    "    x = gsub(\"'\", \" \", x)\n",
    "\n",
    "    # remove punctuation except @, #, _, -\n",
    "    x = gsub(\"@\", \"AAAAAAAAAAA\", x)\n",
    "    x = gsub(\"#\", \"BBBBBBBBBBB\", x)\n",
    "    x = gsub(\"_\", \"CCCCCCCCCCC\", x)\n",
    "    x = gsub(\"-\", \"DDDDDDDDDDD\", x)\n",
    "    x = gsub(\"[[:punct:]]\", \" \", x)\n",
    "    x = gsub(\"AAAAAAAAAAA\", \"@\", x)\n",
    "    x = gsub(\"BBBBBBBBBBB\", \"#\", x)\n",
    "    x = gsub(\"CCCCCCCCCCC\", \"_\", x)\n",
    "    x = gsub(\"DDDDDDDDDDD\", \"-\", x)\n",
    "            \n",
    "    # correcting the spaces after the conserved @\n",
    "    x = gsub(\"@ \", \"@\", x)\n",
    "            \n",
    "    # correcting the spaces after the conserved _\n",
    "    x = gsub(\"_ \", \"_\", x)\n",
    "            \n",
    "    # correcting the spaces after the conserved -\n",
    "    x = gsub(\"- \", \"-\", x)\n",
    "    \n",
    "    # remove numbers/Digits\n",
    "    x = gsub(\"[[:digit:]]\", \"\", x)\n",
    "    \n",
    "    # remove tabs\n",
    "    x = gsub(\"[ |\\t]{2,}\", \" \", x)\n",
    "            \n",
    "    # remove blank spaces at the beginning/end\n",
    "    x = gsub(\"^ \", \"\", x)  \n",
    "    x = gsub(\" $\", \"\", x)\n",
    "    \n",
    "    \n",
    "    # As we have already a column indicating if the tweet is a retweet or not \n",
    "    # we can remove \"RT @xxx\" in the tweet header\n",
    "    x = gsub(\"rt @\\\\w+ *\", \"\", x)\n",
    "    x = gsub('\\\\b\\\\w{1,3}\\\\s','', x)\n",
    "            \n",
    "    # remove double spaces\n",
    "    x = gsub(\"  \", \" \", x)\n",
    "    x = gsub(\"  \", \" \", x)\n",
    "    return(x)\n",
    "}\n",
    "                             \n",
    "tweets$text <- clean_text(tweets$text)\n",
    "head(tweets, n = 293)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sum(is.na(tweets$text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweets = na.omit(tweets)\n",
    "tweets$X <- NULL\n",
    "nrow(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "col = tweets$text\n",
    "at.pattern = \"@\\\\w+ *\"\n",
    "have.at = grep(x = col, pattern = at.pattern)\n",
    "at.matches = gregexpr(pattern = at.pattern,\n",
    "                        text = col[have.at])\n",
    "extracted.at = regmatches(x = col[have.at], m = at.matches)\n",
    "\n",
    "# most frequent words\n",
    "mfw = sort(unlist(extracted.at), decreasing=TRUE)\n",
    "mfw = gsub(\" \", \"\", mfw)\n",
    "top40_user_called = sort(table(unlist(mfw)), decreasing=TRUE)\n",
    "head(top40_user_called, n = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top5 = head(top40_user_called, n = 5)\n",
    "barplot(sort(top5), border=NA, las=2, main=\"Top 5 most frequent word\", cex.main=1, horiz=TRUE, col= \"darkblue\", cex.names=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "at.pattern = \"[a-zA-Z]\\\\w+ *\"\n",
    "have.at = grep(x = col, pattern = at.pattern)\n",
    "at.matches = gregexpr(pattern = at.pattern,\n",
    "                        text = col[have.at])\n",
    "extracted.at = regmatches(x = col[have.at], m = at.matches)\n",
    "\n",
    "# most frequent words\n",
    "mfw = sort(unlist(extracted.at), decreasing=TRUE)\n",
    "mfw = gsub(\" \", \"\", mfw)\n",
    "w = sort(table(unlist(mfw)), decreasing=TRUE)\n",
    "\n",
    "number_Top = function(number){\n",
    "  topWord = head(w, n = number)\n",
    "  topWord = sort(topWord, decreasing=FALSE) \n",
    "  return(topWord)\n",
    "}\n",
    "\n",
    "top15 = number_Top(15)\n",
    "barplot(top15, border=NA, las=2, main=\"Top 15 most frequent word\", cex.main=1, horiz=TRUE, col= \"darkblue\", cex.names=0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#tweets = tweets[-(483), ]\n",
    "nrow(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "library(RSentiment)\n",
    "#library(sentiment)\n",
    "\n",
    "sentences = tweets$text\n",
    "\n",
    "#tweets$score <- calculate_score(tweets$text)\n",
    "z = head(tweets$text, n=870)\n",
    "classe_emo = calculate_score(z)\n",
    "classe_emo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#x = data.frame(classe_emo)\n",
    "#x\n",
    "#tweets$Emotion = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#install.packages(\"wordcloud\")\n",
    "#install.packages(\"SnowballC\")\n",
    "library(SnowballC)\n",
    "library(wordcloud)\n",
    "\n",
    "top50 = number_Top(50)\n",
    "wordcloud(names(top50), top50, min.freq=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#require(devtools)\n",
    "#install_github(\"lchiffon/wordcloud2\")\n",
    "library(wordcloud2)\n",
    "\n",
    "top100 = number_Top(100)\n",
    "cat(\"The letterCloud function does not work on Jupyter notebook, if you are using markdown, you can uncomment this line.\")\n",
    "#letterCloud(top100, word = \"PS\", wordSize = 1)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
